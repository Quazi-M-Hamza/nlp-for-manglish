{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.0.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/ubuntu/gaurav/in/fire/code-mixed-enma/classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Ithu ikkayude script aanu..   Uttopiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Varunnathu manthriyo bhadano alla rajavanu ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>‡¥á‡¥∑‡µç‡¥ü‡¥Æ‡¥æ‡¥£‡µç. But ‡¥ö‡¥ø‡¥≤ ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ over actigalle ‡¥é‡¥®‡µç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>enna look a rajuettaaaaa............ promisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>‡¥á‡¥§‡µç ‡¥Æ‡µÇ‡¥û‡µç‡¥ö‡µÅ‡¥Ç ‡¥â‡¥±‡¥™‡µç‡¥™‡µç  ‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥ü‡µç‡¥∞‡µà‡µá‡¥≤‡µº</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1\n",
       "0  Not_offensive              Ithu ikkayude script aanu..   Uttopiya\n",
       "1  Not_offensive    Varunnathu manthriyo bhadano alla rajavanu ra...\n",
       "2  Not_offensive    ‡¥á‡¥∑‡µç‡¥ü‡¥Æ‡¥æ‡¥£‡µç. But ‡¥ö‡¥ø‡¥≤ ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ over actigalle ‡¥é‡¥®‡µç...\n",
       "3  Not_offensive    enna look a rajuettaaaaa............ promisin...\n",
       "4       Offensive               ‡¥á‡¥§‡µç ‡¥Æ‡µÇ‡¥û‡µç‡¥ö‡µÅ‡¥Ç ‡¥â‡¥±‡¥™‡µç‡¥™‡µç  ‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥ü‡µç‡¥∞‡µà‡µá‡¥≤‡µº"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'../hasoc_task_1/ml-Hasoc-offensive-train.csv', sep='\\t', header=None)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>‡¥®‡¥≤‡µç‡¥≤ ‡¥ä‡¥Æ‡µç‡¥™‡¥ø‡¥Ø bgm ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÅ ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>Lucifer njngal randum kayyum neeti sweekarich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Evideo oru Hollywood story varunnilleee. Oru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>ithre ullo mattavanmarude power ü§£ü§£ü§£ dislike d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Prathi poovan kozhi teaser kandittu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1\n",
       "0       Offensive                 ‡¥®‡¥≤‡µç‡¥≤ ‡¥ä‡¥Æ‡µç‡¥™‡¥ø‡¥Ø bgm ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÅ ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÇ...\n",
       "1       Offensive   Lucifer njngal randum kayyum neeti sweekarich...\n",
       "2  Not_offensive    Evideo oru Hollywood story varunnilleee. Oru ...\n",
       "3  Not_offensive    ithre ullo mattavanmarude power ü§£ü§£ü§£ dislike d...\n",
       "4  Not_offensive                 Prathi poovan kozhi teaser kandittu"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(path/'../hasoc_task_1/ml-Hasoc-offensive-dev.csv', sep='\\t', header=None)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_1</td>\n",
       "      <td>Theatoril climax maathram kaanichal mathiyallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_2</td>\n",
       "      <td>Shah Rukh Khan inte FAN cinema de cheriya samy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_3</td>\n",
       "      <td>Heavy Stills onnum oru rekshem illa adipoli fd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_4</td>\n",
       "      <td>Eee trailer njan ethra pravishyam nokiyann eni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_5</td>\n",
       "      <td>Ikka ethu engane sathikunu enna oru mass I lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  ml_1  Theatoril climax maathram kaanichal mathiyallo...\n",
       "1  ml_2  Shah Rukh Khan inte FAN cinema de cheriya samy...\n",
       "2  ml_3  Heavy Stills onnum oru rekshem illa adipoli fd...\n",
       "3  ml_4  Eee trailer njan ethra pravishyam nokiyann eni...\n",
       "4  ml_5  Ikka ethu engane sathikunu enna oru mass I lov..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_1/ml_mixedscript_Hascoc_offensive_test_without_label.csv', header=None)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 2), (400, 2), (400, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Not_offensive ': 2633, 'Offensive': 567})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Not_offensive ': 328, 'Offensive': 72})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train, df_valid])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedMalayalamTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " ',',\n",
       " '‡µΩ',\n",
       " '‚ñÅthe',\n",
       " '‡µº',\n",
       " '‚ñÅ',\n",
       " '‡µª',\n",
       " 's',\n",
       " '‚ñÅ‚Ä¢',\n",
       " '‚ñÅof',\n",
       " '‡µæ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25,000 is the vocab size that we chose in sentencepiece\n",
    "mlen_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='mlen', tok_func=CodeMixedMalayalamTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html>,\n",
       "  <function fastai.text.transform.replace_rep>,\n",
       "  <function fastai.text.transform.replace_wrep>,\n",
       "  <function fastai.text.transform.spec_add_spaces>,\n",
       "  <function fastai.text.transform.rm_useless_spaces>,\n",
       "  <function __main__.lower_case_everything>,\n",
       "  <function __main__.handle_all_caps>,\n",
       "  <function __main__.handle_upper_case_first_letter>],\n",
       " [<function fastai.text.transform.replace_all_caps>,\n",
       "  <function fastai.text.transform.deal_caps>])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅtell‚ñÅme‚ñÅabout‚ñÅtour‚ñÅself,‚ñÅmujhe‚ñÅjaanna‚ñÅhai'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n",
    "''.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or ‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº ‚ñÅx x bo s ‚ñÅi k kha ‚ñÅme s s ‚ñÅa anu ‚ñÅ xxunk ‚ñÅmam ook kha ‚ñÅ xxunk ‚ñÅd q ‚ñÅx x bo s ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡¥®‡µç ‚ñÅ‡¥ï‡µã‡¥Æ‡¥°‡¥ø ‚ñÅ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Æ‡¥≤‡µç‡¥≤ ‚ñÅ‡¥∏ ‡µÄ‡¥∞‡¥ø‡¥Ø ‡¥∏‡µç ‚ñÅ‡¥±‡µã ‡¥≥ ‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç ‚ñÅ‡¥µ ‡¥¥ ‡¥ô‡µç‡¥ô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bo s ‚ñÅ1 ‚ñÅdivas am ‚ñÅ3 l ‚ñÅku du tal ‚ñÅtavan e ‚ñÅkan una var ‚ñÅa ro kke ‚ñÅund ‚ñÅx x bo s ‚ñÅni na kki ni ‚ñÅmalayalam ‚ñÅin d ru sti yil ‚ñÅki da nn ‚ñÅpo la kka an ‚ñÅpattu menn ‚ñÅtho nn unnund o ‚ñÅbo sse ‚ñÅenna ‚ñÅchodya th inu ‚ñÅoru ‚ñÅa da ar ‚ñÅmaru padi ‚ñÅpra the ek shichu ‚ñÅx x bo s ‚ñÅtha rik ida ‚ñÅsab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>‚ñÅkanda ‚ñÅmalaya ly ‚ñÅchu nk s ‚ñÅud enkil ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅadi ‚ñÅoru ‚ñÅlike ‚ñÅx x bo s ‚ñÅadi poli ‚ñÅmass ‚ñÅsuper b ‚ñÅki du ‚ñÅmammootty ‚ñÅpoli ch ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk ‚ñÅmass ‚ñÅa ay itund ‚ñÅtrai ler ‚ñÅpa kka ‚ñÅpoli ‚ñÅx x bo s ‚ñÅi thu ‚ñÅraja yu de ‚ñÅ3 ‚ñÅstrong ‚ñÅall a ‚ñÅet tan de ‚ñÅlu ci fer ‚ñÅx x bo s ‚ñÅ‡¥ö‡µá ‡¥ü‡µç‡¥ü ‡¥®‡µç‡¥Æ‡¥æ‡¥∞ ‡µá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>‚ñÅ xxrep ‚ñÅ6 ‚ñÅ. ‚ñÅx x bo s ‚ñÅkala kki ‚ñÅi thu ‚ñÅbox ‚ñÅof i ce ‚ñÅa aghosha m ‚ñÅa ayirik kum ‚ñÅx x bo s ‚ñÅ‡¥é‡¥§‡µç‡¥∞ ‚ñÅ‡¥ï‡¥£‡µç‡¥ü ‡¥ø‡¥ü‡µç‡¥ü‡µÅ‡¥Ç ‚ñÅ‡¥Æ‡¥§‡¥ø ‡¥Ø‡¥æ‡¥µ ‡¥æ‡¥§‡µç‡¥§ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥Ö ‚ñÅ‡¥ü‡¥æ ‡µº ‚ñÅit em ‚ñÅx x bo s ‚ñÅb g m ‚ñÅuru ‚ñÅraksha ‚ñÅill ‚ñÅ xxrep ‚ñÅ4 ‚ñÅa ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ. ‚ñÅsu shi n ‚ñÅshyam ‚ñÅtouch ‚ñÅpole . ‚ñÅx x bo s ‚ñÅde c ‚ñÅ12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>‚ñÅx x bo s ‚ñÅ5 ‚ñÅmillion ‚ñÅa yo ‚ñÅne ‚ñÅno kkan ‚ñÅvann avar ‚ñÅe thra ‚ñÅparu ‚ñÅn de ‚ñÅx x bo s ‚ñÅ‡¥ö‡¥æ‡¥®‡¥≤ ‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥™‡µá‡¥∞‡µç ‚ñÅ‡¥∂‡µç‡¥∞‡¥¶‡µç‡¥ß ‡¥ø‡¥ö‡µç‡¥ö ‡¥µ‡µº ‡¥ï‡µç‡¥ï‡µÅ ‚ñÅ‡¥≤‡µà ‡¥ï‡µç‡¥ï‡µç ‚ñÅ‡¥Ö‡¥ü‡¥ø ‡¥ï‡µç‡¥ï‡¥æ‡¥®‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥∏‡µç‡¥•‡¥≤‡¥Ç . . . ‚ñÅx x bo s ‚ñÅenik um ‚ñÅente ‚ñÅfamily ‚ñÅk kum ‚ñÅishtappett illa . . . ‚ñÅdialogue s ‚ñÅonnu m ‚ñÅprop er ‚ñÅa ayi ‚ñÅmana s ila ayi lla . . ‚ñÅ njan ‚ñÅprakasha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(25000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: LMTextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(25000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the pretrained language model on hindi wikipedia\n",
    "learn.load('../../dataset_preparation/models/best_model', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning the prtrained LM on current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 00:09<00:02]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.475304</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.444173</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.067534</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.764607</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11' class='' max='22', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [11/22 00:01<00:01 7.2025]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.785672</td>\n",
       "      <td>5.180454</td>\n",
       "      <td>0.227307</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.175614</td>\n",
       "      <td>4.917291</td>\n",
       "      <td>0.246577</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.909992</td>\n",
       "      <td>4.443356</td>\n",
       "      <td>0.294196</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.650443</td>\n",
       "      <td>4.187945</td>\n",
       "      <td>0.319345</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.449930</td>\n",
       "      <td>4.070615</td>\n",
       "      <td>0.330060</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.321851</td>\n",
       "      <td>4.052440</td>\n",
       "      <td>0.331548</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evideo oru Hollywood story w ill ‚ñÅnegative ‚ñÅ ‚ñÅ. ‚ñÅoru ‚ñÅavatara ‚ñÅpirann'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Evideo oru Hollywood story',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>‚ñÅx x bo s ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman</td>\n",
       "      <td>Not_offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>‚ñÅx x bo s ‚ñÅ‡¥®‡¥æ ‡¥£ ‡¥Æ ‡µÅ‡¥£‡µç‡¥ü‡µã ‡¥ü‡¥æ ‚ñÅ‡¥ö‡µÜ ‡¥±‡µç‡¥± ‡¥ï‡¥≥‡µÜ ‚ñÅ‡¥á ‡¥Æ‡µç‡¥Æ‡¥æ ‡¥§‡¥ø‡¥∞‡¥ø ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥™‡¥∞‡¥ø‡¥™‡¥æ‡¥ü‡¥ø ‚ñÅ‡¥ï‡¥æ‡¥£‡¥ø‡¥ï‡µç‡¥ï ‡¥æ‡µª ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡¥≤‡µÜ ‡µº ‚ñÅ‡¥Ö‡¥§‡µç ‚ñÅ‡¥®‡¥ø ‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µÅ ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ö‡¥±‡¥ø‡¥Ø ‡¥æ‡¥Ç ‚ñÅ‡¥é‡¥®‡µç‡¥® ‡¥ø‡¥ü‡µç‡¥ü‡µÅ‡¥Ç ‚ñÅ. ‚ñÅ‡¥à ‚ñÅ‡¥™‡¥ü ‡¥Æ ‡µä‡¥ï‡µç‡¥ï‡µÜ ‚ñÅ‡¥á‡¥±‡¥ô‡µç‡¥ô ‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü‡µº‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥±‡¥ø‡¥Ø ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ. ‚ñÅ‡¥§‡µÄ ‡¥Ø‡µá‡¥±‡µç‡¥± ‡¥±‡¥ø‡µΩ ‚ñÅ‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø ‡¥æ‡µΩ ‚ñÅ‡¥Ü‡¥≥‡µÅ‡¥ï‡µæ ‚ñÅ‡¥é‡¥ü‡µÅ‡¥§‡µç‡¥§ ‡¥ø‡¥ü‡µç‡¥ü ‡¥≤ ‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥§‡µÅ ‡¥ï‡¥¥‡¥ø‡¥û‡µç‡¥û ‡¥æ‡¥£‡µç ‚ñÅ‡¥Ü ‡¥Æ‡¥ø‡¥® ‡¥§‡¥æ ‡¥§‡µç‡¥§‡¥æ ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥∞‡¥µ ‡µç ‚ñÅ‡¥ö‡¥∞‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥é‡¥ô‡µç‡¥ô‡¥®‡µÜ ‚ñÅ‡¥ï‡¥æ‡¥£‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>‚ñÅx x bo s ‚ñÅi th inum ‚ñÅmatra m ‚ñÅnall a ‚ñÅreview ‚ñÅki tta a an ‚ñÅen thu ‚ñÅthe nga yaa ‚ñÅe e ‚ñÅpada thi lulla the nn ‚ñÅenik ‚ñÅmaa tra ano ‚ñÅtho nn iya th . . ‚ñÅaake ‚ñÅrasa ma ayi tt ‚ñÅtho nn iya th ‚ñÅ2 . . . ‚ñÅ3 ‚ñÅscene s ‚ñÅmatra m . . ‚ñÅoru ‚ñÅ50 ‚ñÅpercent ‚ñÅdia log ‚ñÅonnu m ‚ñÅenik ‚ñÅmanassil a ayi lla</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>‚ñÅx x bo s ‚ñÅi th inum ‚ñÅmatra m ‚ñÅnall a ‚ñÅreview ‚ñÅki tta a an ‚ñÅen thu ‚ñÅthe nga yaa ‚ñÅe e ‚ñÅpada thi lulla the nn ‚ñÅenik ‚ñÅmaa tra ano ‚ñÅtho nn iya th . . ‚ñÅaake ‚ñÅrasa ma ayi tt ‚ñÅtho nn iya th ‚ñÅ2 . . . ‚ñÅ3 ‚ñÅscene s ‚ñÅmatra m . . ‚ñÅoru ‚ñÅ50 ‚ñÅpercent ‚ñÅdia log ‚ñÅonnu m ‚ñÅenik ‚ñÅmanassil a ayi lla</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>‚ñÅx x bo s ‚ñÅ xxunk p rit vi ‚ñÅrecent ‚ñÅinterview ‚ñÅstory ‚ñÅtre ad ‚ñÅpar j irunnu ‚ñÅe th nd u ‚ñÅmain ‚ñÅkatha ‚ñÅth nn ea ‚ñÅapp ol ‚ñÅvi ch rich tha ‚ñÅe ger u th nn ea ‚ñÅall ea ‚ñÅproducer ‚ñÅennu ‚ñÅenni tum ‚ñÅe ntha ‚ñÅe thu ‚ñÅok ‚ñÅpar nju ‚ñÅpada the ‚ñÅkollu n thu ‚ñÅennu ‚ñÅe e ‚ñÅci mai l ‚ñÅ ulla ‚ñÅage ru da ‚ñÅcon fi d</td>\n",
       "      <td>Not_offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.417806</td>\n",
       "      <td>0.334152</td>\n",
       "      <td>0.429945</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.321491</td>\n",
       "      <td>0.223157</td>\n",
       "      <td>0.687972</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.246178</td>\n",
       "      <td>0.178636</td>\n",
       "      <td>0.776569</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213831</td>\n",
       "      <td>0.085446</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150778</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.965953</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>0.030141</td>\n",
       "      <td>0.974499</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080028</td>\n",
       "      <td>0.028110</td>\n",
       "      <td>0.983021</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9375.\n",
      "Better model found at epoch 1 with accuracy value: 0.9775000214576721.\n",
      "Better model found at epoch 2 with accuracy value: 0.9900000095367432.\n",
      "Better model found at epoch 3 with accuracy value: 0.9925000071525574.\n",
      "Better model found at epoch 4 with accuracy value: 0.9950000047683716.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅi thu ‚ñÅ ikkayu de ‚ñÅscript ‚ñÅa anu . . ‚ñÅutt op iya,‚ñÅx x bo s ‚ñÅvarunnat hu ‚ñÅman th ri yo ‚ñÅbha da no ‚ñÅall a ‚ñÅraja vanu ‚ñÅraja vu,‚ñÅx x bo s ‚ñÅ‡¥á‡¥∑‡µç‡¥ü ‡¥Æ‡¥æ‡¥£‡µç . ‚ñÅbut ‚ñÅ‡¥ö‡¥ø‡¥≤ ‚ñÅ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥Ø‡¥ø‡µΩ ‚ñÅover ‚ñÅact i gal le ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥Ç . .,‚ñÅx x bo s ‚ñÅenna ‚ñÅlook ‚ñÅa ‚ñÅraj u e tt ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ xxrep ‚ñÅ12 ‚ñÅ. ‚ñÅpro mis ing ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥Æ‡µÇ ‡¥û‡µç‡¥ö ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µç ‚ñÅ‡¥é‡¥®‡µç‡¥§ ‡µç ‚ñÅ‡¥ä ‡¥≥ ‚ñÅ‡¥ü‡µç‡¥∞‡µà ‡µá ‡¥≤ ‡µº\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥ä ‡¥Æ‡µç‡¥™‡¥ø ‡¥Ø ‚ñÅb g m ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü‡µÅ ‚ñÅ‡¥ü‡µÅ ‚ñÅ ‡¥ü‡µç‡¥ü ‡µÇ . . .,‚ñÅx x bo s ‚ñÅlu ci fer ‚ñÅ nj ngal ‚ñÅrandu m ‚ñÅkay yu m ‚ñÅne eti ‚ñÅswe e kar ichu . . ‚ñÅmarichu . . ‚ñÅmath am ‚ñÅparayunn a ‚ñÅsang i kal ‚ñÅke ri ‚ñÅdis like ‚ñÅadukk uva aa . . . ‚ñÅoru ‚ñÅmy rum ‚ñÅnada kkulla ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ.,‚ñÅx x bo s ‚ñÅe vid eo ‚ñÅoru ‚ñÅhollywood ‚ñÅstory ‚ñÅvarunn ille e e . ‚ñÅoru ‚ñÅd b t .,‚ñÅx x bo s ‚ñÅi th re ‚ñÅull o ‚ñÅmat tavan maru de ‚ñÅpower ‚ñÅ xxunk ‚ñÅdis like ‚ñÅdis like,‚ñÅx x bo s ‚ñÅpra thi ‚ñÅpoo van ‚ñÅko zhi ‚ñÅtea s er ‚ñÅkand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "‚ñÅx x bo s ‚ñÅthe ator il ‚ñÅcli ma x ‚ñÅmaa th ram ‚ñÅkaa ni chal ‚ñÅmath iya llo ‚ñÅen y . . . ‚ñÅany ‚ñÅway s ‚ñÅgood ‚ñÅtra il or,‚ñÅx x bo s ‚ñÅshah ‚ñÅrukh ‚ñÅkhan ‚ñÅinte ‚ñÅfan ‚ñÅcinema ‚ñÅde ‚ñÅcheriya ‚ñÅsam yam ‚ñÅ kanu nu xxunk .,‚ñÅx x bo s ‚ñÅheavy ‚ñÅstill s ‚ñÅonnu m ‚ñÅoru ‚ñÅre ksh em ‚ñÅi lla ‚ñÅadi poli ‚ñÅf d f s ‚ñÅ lock ed,‚ñÅx x bo s ‚ñÅe e e ‚ñÅtrai ler ‚ñÅ njan ‚ñÅe thra ‚ñÅpravishya m ‚ñÅno ki ya nn ‚ñÅenik ku ‚ñÅari y illa ‚ñÅni ngal um ‚ñÅ ing ane ‚ñÅtanne yanu ‚ñÅi kka ‚ñÅis ttam,‚ñÅx x bo s ‚ñÅi kka ‚ñÅe thu ‚ñÅeng ane ‚ñÅsa thi ku nu ‚ñÅenna ‚ñÅoru ‚ñÅmass ‚ñÅi ‚ñÅlove ‚ñÅyou ‚ñÅi kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Not_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¥®‡¥≤‡µç‡¥≤ ‡¥ä‡¥Æ‡µç‡¥™‡¥ø‡¥Ø bgm ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÅ ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÇ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>0.000217882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucifer njngal randum kayyum neeti sweekarich...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>0.982383</td>\n",
       "      <td>0.0176174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evideo oru Hollywood story varunnilleee. Oru ...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0211621</td>\n",
       "      <td>0.978838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ithre ullo mattavanmarude power ü§£ü§£ü§£ dislike d...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0543507</td>\n",
       "      <td>0.945649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prathi poovan kozhi teaser kandittu</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.00234966</td>\n",
       "      <td>0.99765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query    actual_label  \\\n",
       "0                 ‡¥®‡¥≤‡µç‡¥≤ ‡¥ä‡¥Æ‡µç‡¥™‡¥ø‡¥Ø bgm ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÅ ‡¥ü‡µÅ ‡¥ü‡µç‡¥ü‡µÇ...       Offensive   \n",
       "1   Lucifer njngal randum kayyum neeti sweekarich...       Offensive   \n",
       "2   Evideo oru Hollywood story varunnilleee. Oru ...  Not_offensive    \n",
       "3   ithre ullo mattavanmarude power ü§£ü§£ü§£ dislike d...  Not_offensive    \n",
       "4                Prathi poovan kozhi teaser kandittu  Not_offensive    \n",
       "\n",
       "  predicted_label   Offensive Not_offensive   \n",
       "0       Offensive    0.999782    0.000217882  \n",
       "1       Offensive    0.982383      0.0176174  \n",
       "2  Not_offensive    0.0211621       0.978838  \n",
       "3  Not_offensive    0.0543507       0.945649  \n",
       "4  Not_offensive   0.00234966        0.99765  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test[1]), 'actual_label': list(df_test[0]), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[0]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830208371799483"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577464"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], labels=['Not_offensive ', 'Offensive'], pos_label='Offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Not_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_1</td>\n",
       "      <td>Theatoril climax maathram kaanichal mathiyallo...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.000304782</td>\n",
       "      <td>0.999695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_2</td>\n",
       "      <td>Shah Rukh Khan inte FAN cinema de cheriya samy...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0220021</td>\n",
       "      <td>0.977998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_3</td>\n",
       "      <td>Heavy Stills onnum oru rekshem illa adipoli fd...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.000517501</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_4</td>\n",
       "      <td>Eee trailer njan ethra pravishyam nokiyann eni...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0072398</td>\n",
       "      <td>0.99276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_5</td>\n",
       "      <td>Ikka ethu engane sathikunu enna oru mass I lov...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>5.54634e-05</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text           label  \\\n",
       "0  ml_1  Theatoril climax maathram kaanichal mathiyallo...  Not_offensive    \n",
       "1  ml_2  Shah Rukh Khan inte FAN cinema de cheriya samy...  Not_offensive    \n",
       "2  ml_3  Heavy Stills onnum oru rekshem illa adipoli fd...  Not_offensive    \n",
       "3  ml_4  Eee trailer njan ethra pravishyam nokiyann eni...  Not_offensive    \n",
       "4  ml_5  Ikka ethu engane sathikunu enna oru mass I lov...  Not_offensive    \n",
       "\n",
       "     Offensive Not_offensive   \n",
       "0  0.000304782       0.999695  \n",
       "1    0.0220021       0.977998  \n",
       "2  0.000517501       0.999483  \n",
       "3    0.0072398        0.99276  \n",
       "4  5.54634e-05       0.999945  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_1/ml_mixedscript_Hascoc_offensive_test_without_label.csv', header=None)\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'id': list(df_test[0]), 'text': list(df_test[1]), 'label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[0]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['label']=='Offensive'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('test_res_2nd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Offensive, tensor(1), tensor([4.1480e-04, 9.9959e-01]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Dislike adikunna mammunikale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
